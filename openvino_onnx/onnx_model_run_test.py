
import argparse
import onnx
import onnxruntime as ort
import numpy as np

def test_onnx_model(onnx_path, batch_size=1, default_hw=224):
    """
    DINOv3 ONNX æ¨¡å‹æµ‹è¯•å·¥å…·
    è‡ªåŠ¨æ ¹æ®æ¨¡å‹è¾“å…¥ shape æ„é€ éšæœºè¾“å…¥ï¼Œå¹¶éªŒè¯æ¨ç†æ˜¯å¦å¯ç”¨ã€‚
    
    Args:
        onnx_path (str): ONNX æ¨¡å‹è·¯å¾„
        batch_size (int): æµ‹è¯• batch sizeï¼ˆæ›¿æ¢è¾“å…¥çš„ç¬¬ 0 ç»´ï¼‰
        default_hw (int): é«˜/å®½é»˜è®¤å€¼ï¼Œå¦‚æœ shape ä¸ç¡®å®šåˆ™ä½¿ç”¨
    """
    # -----------------------------
    # 1. æ£€æŸ¥ ONNX æ¨¡å‹ç»“æ„
    # -----------------------------
    try:
        model = onnx.load(onnx_path)
        onnx.checker.check_model(model)
        print(f"âœ… ONNX æ¨¡å‹ç»“æ„æ£€æŸ¥é€šè¿‡: {onnx_path}")
    except onnx.checker.ValidationError as e:
        print(f"âŒ ONNX æ¨¡å‹æ£€æŸ¥å¤±è´¥: {e}")
        return

    # -----------------------------
    # 2. ONNX Runtime æ¨ç†
    # -----------------------------
    ort_session = ort.InferenceSession(onnx_path)

    # è·å–è¾“å…¥ä¿¡æ¯
    inputs_info = ort_session.get_inputs()
    outputs_info = ort_session.get_outputs()

    feed_dict = {}

    for inp in inputs_info:
        name = inp.name
        shape = []
        for i, dim in enumerate(inp.shape):
            if isinstance(dim, int):
                shape.append(dim)
            else:
                # batch ç»´
                if i == 0:
                    shape.append(batch_size)
                # å›¾åƒé€šé“
                elif i == 1:
                    shape.append(3)
                # é«˜/å®½
                else:
                    shape.append(default_hw)

        # ONNX dtype è½¬ numpy dtype
        dtype = np.float32 if "float" in inp.type else np.int64

        # æ„é€ éšæœºè¾“å…¥
        if dtype == np.float32:
            dummy_input = np.random.randn(*shape).astype(dtype)
        else:
            dummy_input = np.random.randint(0, 100, size=shape, dtype=dtype)

        feed_dict[name] = dummy_input
        print(f"ğŸ”¹ è¾“å…¥ [{name}] shape={shape}, dtype={dtype}")

    # è·å–è¾“å‡ºåç§°
    output_names = [out.name for out in outputs_info]

    # æ¨ç†
    results = ort_session.run(output_names, feed_dict)

    # è¾“å‡ºç»“æœä¿¡æ¯
    for name, result in zip(output_names, results):
        print(f"âœ… è¾“å‡º [{name}] shape={result.shape}, dtype={result.dtype}")
        print("ç¤ºä¾‹è¾“å‡º:\n", result[:2])  # æ‰“å°å‰ 2 æ¡ç»“æœ


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="DINOv3 ONNX æ¨¡å‹æµ‹è¯•å·¥å…·")
    parser.add_argument("--onnx_path", type=str, required=True, help="ONNX æ¨¡å‹è·¯å¾„")
    parser.add_argument("--batch_size", type=int, default=1, help="æµ‹è¯• batch size (é»˜è®¤=1)")
    parser.add_argument("--default_hw", type=int, default=256, help="é»˜è®¤å›¾åƒé«˜/å®½ (é»˜è®¤=224)")
    args = parser.parse_args()

    test_onnx_model(args.onnx_path, args.batch_size, args.default_hw)
