import argparse
import onnx
import onnxruntime as ort
import numpy as np

def test_onnx_model(onnx_path, batch_size=1):
    """
    é€šç”¨ ONNX æ¨¡å‹æµ‹è¯•å·¥å…·
    è‡ªåŠ¨æ ¹æ®æ¨¡å‹è¾“å…¥ shape æ„é€ éšæœºè¾“å…¥ï¼Œå¹¶éªŒè¯æ¨ç†æ˜¯å¦å¯ç”¨ã€‚
    
    Args:
        onnx_path (str): ONNX æ¨¡å‹è·¯å¾„
        batch_size (int): æµ‹è¯• batch sizeï¼ˆä¼šæ›¿æ¢è¾“å…¥çš„ç¬¬ä¸€ä¸ªç»´åº¦ï¼‰
    """
    # -----------------------------
    # 1. æ£€æŸ¥ ONNX æ¨¡å‹ç»“æ„
    # -----------------------------
    try:
        model = onnx.load(onnx_path)
        onnx.checker.check_model(model)
        print(f"âœ… ONNX æ¨¡å‹ç»“æ„æ£€æŸ¥é€šè¿‡: {onnx_path}")
    except onnx.checker.ValidationError as e:
        print(f"âŒ ONNX æ¨¡å‹æ£€æŸ¥å¤±è´¥: {e}")
        return

    # -----------------------------
    # 2. ONNX Runtime æ¨ç†
    # -----------------------------
    ort_session = ort.InferenceSession(onnx_path)

    # è·å–è¾“å…¥ä¿¡æ¯
    inputs_info = ort_session.get_inputs()
    outputs_info = ort_session.get_outputs()

    feed_dict = {}

    for inp in inputs_info:
        name = inp.name
        shape = [dim if isinstance(dim, int) else batch_size if i == 0 else 1 
                 for i, dim in enumerate(inp.shape)]
        dtype = np.float32 if inp.type == "tensor(float)" else np.int64

        # æ„é€ éšæœºè¾“å…¥
        if dtype == np.float32:
            dummy_input = np.random.randn(*shape).astype(dtype)
        else:
            dummy_input = np.random.randint(0, 100, size=shape, dtype=dtype)

        feed_dict[name] = dummy_input
        print(f"ğŸ”¹ è¾“å…¥ [{name}] shape={shape}, dtype={dtype}")

    # è·å–è¾“å‡ºåç§°
    output_names = [out.name for out in outputs_info]

    # æ¨ç†
    results = ort_session.run(output_names, feed_dict)

    # è¾“å‡ºç»“æœä¿¡æ¯
    for name, result in zip(output_names, results):
        print(f"âœ… è¾“å‡º [{name}] shape={result.shape}, dtype={result.dtype}")
        print("ç¤ºä¾‹è¾“å‡º:\n", result[:2])  # æ‰“å°å‰ 2 æ¡ç»“æœï¼Œé¿å…å¤ªé•¿


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="é€šç”¨ ONNX æ¨¡å‹æµ‹è¯•å·¥å…·")
    parser.add_argument("--onnx_path", type=str, required=True, help="ONNX æ¨¡å‹è·¯å¾„")
    parser.add_argument("--batch_size", type=int, default=1, help="æµ‹è¯• batch size (é»˜è®¤=1)")
    args = parser.parse_args()

    test_onnx_model(args.onnx_path, args.batch_size)
